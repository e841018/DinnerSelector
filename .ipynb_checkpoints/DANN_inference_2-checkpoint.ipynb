{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model import DANN_nasa, DANN_res152\n",
    "from dataset import Real, Image, Image_feature\n",
    "from torch.utils.data import DataLoader\n",
    "import os\n",
    "import torch\n",
    "import random\n",
    "import numpy as np\n",
    "import torch.backends.cudnn as cudnn\n",
    "cudnn.benchmark = True\n",
    "cuda = True if torch.cuda.is_available() else False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function of top k accuarcy\n",
    "def accuracy(output, target, topk=(1,)):\n",
    "    \"\"\"Computes the precision@k for the specified values of k\"\"\"\n",
    "    maxk = max(topk)\n",
    "    batch_size = target.size(0)\n",
    "\n",
    "    _, pred = output.topk(maxk, 1, True, True)\n",
    "    pred = pred.t()\n",
    "    correct = pred.eq(target.view(1, -1).expand_as(pred))\n",
    "\n",
    "    res = []\n",
    "    for k in topk:\n",
    "        correct_k = correct[:k].view(-1).float().sum(0)\n",
    "        res.append(correct_k.mul_(100.0 / batch_size))\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 0\n",
    "\n",
    "batch_size = 256\n",
    "\n",
    "model_root = 'dann_models'\n",
    "\n",
    "data_dir = 'dataset'\n",
    "\n",
    "t_name = 'real'\n",
    "\n",
    "t_dir = os.path.join(data_dir, t_name)\n",
    "t_csv = [os.path.join(t_dir, f) for f in os.listdir(t_dir) if f.endswith('test.csv')][0]\n",
    "print(t_csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.listdir(os.path.join(model_root,'sketch2real'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### key in the models that you want to test ###\n",
    "#model_list = os.listdir(os.path.join(model_root,'sketch2real'))\n",
    "model_list = ['sketch2real_resnet152_best_0.42062.pth', 'sketch2real_resnet152_best_0.48847.pth']\n",
    "###\n",
    "\n",
    "# list that stores all the output tensor after each pth\n",
    "out_list = []\n",
    "\n",
    "# top-1 accuaracy for each pth\n",
    "top_1 = []\n",
    "\n",
    "# top-5 accuaracy for each pth\n",
    "top_5 = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for model in model_list:\n",
    "    \n",
    "    # define model corresponding to the current testing pth\n",
    "\n",
    "    if 'resnet152' in model:\n",
    "\n",
    "        feature_model = 'resnet152'\n",
    "\n",
    "        net = DANN_res152()\n",
    "\n",
    "    elif 'nasnetalarge' in model:\n",
    "\n",
    "        feature_model = 'nasnetalarge'\n",
    "\n",
    "        net = DANN_nasa()\n",
    "        \n",
    "    # build target dataloader\n",
    "\n",
    "    dataset_t = Image_feature(data_dir, t_csv, feature_model)\n",
    "    dataloader_t = DataLoader(dataset=dataset_t, batch_size=batch_size, shuffle=False, num_workers=4)\n",
    "\n",
    "    print('len(dataset_t): ', len(dataset_t))  # total # of target images\n",
    "    print('len(dataloader_t): ', len(dataloader_t))\n",
    "\n",
    "    for i, data in enumerate(dataloader_t):\n",
    "        images, labels = data\n",
    "        print('Image tensor in each batch:', images.shape, images.dtype)\n",
    "        print('Label tensor in each batch:', labels.shape, labels.dtype)\n",
    "        break\n",
    "\n",
    "    # check pth path\n",
    "    model_path = os.path.join(model_root, model.split('_')[0], model)\n",
    "    print(model_path)\n",
    "    \n",
    "    # load pth\n",
    "    net = torch.load(model_path)\n",
    "\n",
    "    net = net.eval()\n",
    "\n",
    "    if cuda:\n",
    "        net = net.cuda()\n",
    "\n",
    "    len_dataloader = len(dataloader_t)\n",
    "    data_target_iter = iter(dataloader_t)\n",
    "    #print('len_dataloader: ', len_dataloader)\n",
    "    \n",
    "    i = 0\n",
    "    n_correct = 0\n",
    "    n_total = 0\n",
    "    while i < len_dataloader:\n",
    "\n",
    "        # test model using target data\n",
    "        data_target = data_target_iter.next()\n",
    "        t_img, t_label = data_target\n",
    "\n",
    "        batch_size = len(t_label)        \n",
    "        class_label = torch.LongTensor(batch_size)\n",
    "\n",
    "        if cuda:\n",
    "            t_img = t_img.cuda()\n",
    "            t_label = t_label.cuda()            \n",
    "            class_label = class_label.cuda()\n",
    "\n",
    "        class_label.resize_as_(t_label).copy_(t_label)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            class_output, _ = net(input_data=t_img, alpha=alpha)\n",
    "\n",
    "        if i == 0:\n",
    "            out_tensor = class_output\n",
    "            out_label = class_label\n",
    "        else:\n",
    "            out_tensor = torch.cat((out_tensor, class_output), 0)\n",
    "            out_label = torch.cat((out_label, class_label), 0)\n",
    "\n",
    "        if i % (len_dataloader//5) == 0:\n",
    "            print('progress: %d%% ' % (i/len_dataloader*100))\n",
    "\n",
    "        i += 1\n",
    "\n",
    "    # gpu to cpu\n",
    "    out_tensor = out_tensor.cpu()\n",
    "    out_label = out_label.cpu() \n",
    "\n",
    "    # append to out_list\n",
    "    out_list.append(out_tensor)\n",
    "\n",
    "    # top k accuarcy & append to top_k list\n",
    "    top_acc = accuracy(out_tensor, out_label, topk=(1,5))\n",
    "    top_1.append(top_acc[0].item())\n",
    "    top_5.append(top_acc[1].item())\n",
    "    \n",
    "    print('top_acc:', top_acc)\n",
    "\n",
    "    print('progress: 100% ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(out_list))\n",
    "print(top_1)\n",
    "print(top_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "same_weight_tensor = torch.zeros(out_list[0].size())\n",
    "top_1_tensor = torch.zeros(out_list[0].size())\n",
    "top_5_tensor = torch.zeros(out_list[0].size())\n",
    "\n",
    "\n",
    "for index, item in enumerate(out_list):\n",
    "    same_weight_tensor += item\n",
    "    top_1_tensor += top_1[index] * item\n",
    "    top_5_tensor += top_5[index] * item\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy(out_list[0], out_label, topk=(1,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy(out_list[1], out_label, topk=(1,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy(same_weight_tensor, out_label, topk=(1,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy(top_1_tensor, out_label, topk=(1,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy(top_5_tensor, out_label, topk=(1,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# one-hot encoding to class label\n",
    "# choose which tensor you want to transform to csv\n",
    "\n",
    "pred = top_1_tensor.data.max(1, keepdim=True)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_list = dataset_t.image_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(image_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "csv_name = s_name+'_'+t_name+'_pred.csv'\n",
    "f = open(csv_name,'w') \n",
    "w = csv.writer(f)\n",
    "title = ['image_name','label']\n",
    "w.writerow(title)\n",
    "for i in range(len(pred)):\n",
    "    content = [image_list[i],pred_list[i]]\n",
    "    w.writerow(content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
